{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14267129,"sourceType":"datasetVersion","datasetId":9104355}],"dockerImageVersionId":31234,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:30:54.737241Z","iopub.execute_input":"2025-12-25T16:30:54.737599Z","iopub.status.idle":"2025-12-25T16:30:59.081414Z","shell.execute_reply.started":"2025-12-25T16:30:54.737568Z","shell.execute_reply":"2025-12-25T16:30:59.080381Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:30:59.083812Z","iopub.execute_input":"2025-12-25T16:30:59.084439Z","iopub.status.idle":"2025-12-25T16:30:59.098369Z","shell.execute_reply.started":"2025-12-25T16:30:59.084326Z","shell.execute_reply":"2025-12-25T16:30:59.097126Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/student-exam-percentages/student_exam_percentage.csv')\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:30:59.099942Z","iopub.execute_input":"2025-12-25T16:30:59.100261Z","iopub.status.idle":"2025-12-25T16:30:59.185249Z","shell.execute_reply.started":"2025-12-25T16:30:59.100234Z","shell.execute_reply":"2025-12-25T16:30:59.183855Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.describe().T","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:30:59.187889Z","iopub.execute_input":"2025-12-25T16:30:59.188286Z","iopub.status.idle":"2025-12-25T16:30:59.235980Z","shell.execute_reply.started":"2025-12-25T16:30:59.188255Z","shell.execute_reply":"2025-12-25T16:30:59.234527Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df.isnull().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:30:59.237377Z","iopub.execute_input":"2025-12-25T16:30:59.237785Z","iopub.status.idle":"2025-12-25T16:30:59.246477Z","shell.execute_reply.started":"2025-12-25T16:30:59.237743Z","shell.execute_reply":"2025-12-25T16:30:59.244978Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df.duplicated().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:30:59.248001Z","iopub.execute_input":"2025-12-25T16:30:59.248411Z","iopub.status.idle":"2025-12-25T16:30:59.276936Z","shell.execute_reply.started":"2025-12-25T16:30:59.248369Z","shell.execute_reply":"2025-12-25T16:30:59.275749Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nsns.boxplot(data=df)\nplt.title(\"Variable Distribution and Outlier Checking\")\nplt.xticks(rotation=45)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:30:59.278296Z","iopub.execute_input":"2025-12-25T16:30:59.278595Z","iopub.status.idle":"2025-12-25T16:30:59.729366Z","shell.execute_reply.started":"2025-12-25T16:30:59.278568Z","shell.execute_reply":"2025-12-25T16:30:59.727787Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set the visual style for the plots\nsns.set(style=\"whitegrid\")\n\n# Create a figure to display histograms of all numerical columns\nplt.figure(figsize=(15, 10))\n\n# Iterate through each column to plot its distribution\nfor i, column in enumerate(df.columns):\n    plt.subplot(3, 2, i + 1)\n    # kde=True adds a kernel density estimate line to see the shape of the distribution\n    sns.histplot(df[column], kde=True, color='skyblue')\n    plt.title(f'Distribution of {column}')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:30:59.731404Z","iopub.execute_input":"2025-12-25T16:30:59.731845Z","iopub.status.idle":"2025-12-25T16:31:01.513388Z","shell.execute_reply.started":"2025-12-25T16:30:59.731784Z","shell.execute_reply":"2025-12-25T16:31:01.512009Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate the correlation matrix\ncorrelation_matrix = df.corr()\nprint(correlation_matrix)\n\n# Visualize the correlations using a heatmap\nplt.figure(figsize=(10, 8))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\nplt.title(\"Correlation Analysis of Student Performance Features\")\nplt.show()\n\n# Focus specifically on how other features relate to the Final Percentage\nprint(\"--- Correlation with Final Percentage ---\")\nprint(correlation_matrix[\"Final_Percentage\"].sort_values(ascending=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:31:01.514627Z","iopub.execute_input":"2025-12-25T16:31:01.514979Z","iopub.status.idle":"2025-12-25T16:31:01.868749Z","shell.execute_reply.started":"2025-12-25T16:31:01.514949Z","shell.execute_reply":"2025-12-25T16:31:01.867656Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a correlation matrix excluding the target variable 'Final_Percentage'\n# I only want to see how independent variables relate to each other\nindependent_variables = df.drop(columns=['Final_Percentage'])\nindependent_corr = independent_variables.corr()\nindependent_corr","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:31:01.872579Z","iopub.execute_input":"2025-12-25T16:31:01.872946Z","iopub.status.idle":"2025-12-25T16:31:01.887526Z","shell.execute_reply.started":"2025-12-25T16:31:01.872912Z","shell.execute_reply":"2025-12-25T16:31:01.886580Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize only the relationships between features\nplt.figure(figsize=(8, 6))\nsns.heatmap(independent_corr, annot=True, cmap='YlGnBu', fmt='.2f')\nplt.title(\"Correlation Between Independent Variables (Check for Multicollinearity)\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:31:01.888731Z","iopub.execute_input":"2025-12-25T16:31:01.889327Z","iopub.status.idle":"2025-12-25T16:31:02.203519Z","shell.execute_reply.started":"2025-12-25T16:31:01.889288Z","shell.execute_reply":"2025-12-25T16:31:02.202448Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:31:02.204903Z","iopub.execute_input":"2025-12-25T16:31:02.205284Z","iopub.status.idle":"2025-12-25T16:31:02.467193Z","shell.execute_reply.started":"2025-12-25T16:31:02.205243Z","shell.execute_reply":"2025-12-25T16:31:02.465931Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define Features (X) and Target (y)\n# X contains the independent variables, y contains the value I want to predict\nX = df.drop(columns=['Final_Percentage'])\ny = df['Final_Percentage']\n# Split the data: 80% for training the model, 20% for testing its performance\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nprint(f\"Training set size: {X_train.shape[0]} samples\")\nprint(f\"Test set size: {X_test.shape[0]} samples\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:31:02.468369Z","iopub.execute_input":"2025-12-25T16:31:02.470266Z","iopub.status.idle":"2025-12-25T16:31:02.484466Z","shell.execute_reply.started":"2025-12-25T16:31:02.470213Z","shell.execute_reply":"2025-12-25T16:31:02.483157Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:31:02.486406Z","iopub.execute_input":"2025-12-25T16:31:02.486853Z","iopub.status.idle":"2025-12-25T16:31:02.521513Z","shell.execute_reply.started":"2025-12-25T16:31:02.486783Z","shell.execute_reply":"2025-12-25T16:31:02.520272Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. Initialize the StandardScaler\nscaler = StandardScaler()\n# 2. Fit the scaler on the training data and transform it\nX_train_scaled = scaler.fit_transform(X_train)\n# 3. Transform the test data using the same scaler\nX_test_scaled = scaler.transform(X_test)\n# Convert them back to DataFrame just to see how they look\nX_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:31:02.523221Z","iopub.execute_input":"2025-12-25T16:31:02.523778Z","iopub.status.idle":"2025-12-25T16:31:02.556967Z","shell.execute_reply.started":"2025-12-25T16:31:02.523729Z","shell.execute_reply":"2025-12-25T16:31:02.555126Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_scaled","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:31:02.558640Z","iopub.execute_input":"2025-12-25T16:31:02.559181Z","iopub.status.idle":"2025-12-25T16:31:02.593304Z","shell.execute_reply.started":"2025-12-25T16:31:02.559137Z","shell.execute_reply":"2025-12-25T16:31:02.591710Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_scaled_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:31:02.594700Z","iopub.execute_input":"2025-12-25T16:31:02.595130Z","iopub.status.idle":"2025-12-25T16:31:02.637333Z","shell.execute_reply.started":"2025-12-25T16:31:02.595075Z","shell.execute_reply":"2025-12-25T16:31:02.634309Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:31:02.639059Z","iopub.execute_input":"2025-12-25T16:31:02.639470Z","iopub.status.idle":"2025-12-25T16:31:02.803981Z","shell.execute_reply.started":"2025-12-25T16:31:02.639427Z","shell.execute_reply":"2025-12-25T16:31:02.802763Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. Initialize the Linear Regression model\nregressor = LinearRegression()\n# 2. Train the model using the scaled training data\nregressor.fit(X_train_scaled, y_train)\n# 3. View the results of the learning process\nprint(\"Model training on scaled data is complete.\")\nprint(f\"Intercept (b0): {regressor.intercept_:.4f}\")\n\n# Creating a Series to see which coefficient belongs to which feature\ncoefficients = pd.Series(regressor.coef_, index=X.columns)\nprint(\"\\n--- Model Coefficients (Importance) ---\")\nprint(coefficients.sort_values(ascending=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:31:02.805230Z","iopub.execute_input":"2025-12-25T16:31:02.805644Z","iopub.status.idle":"2025-12-25T16:31:02.830488Z","shell.execute_reply.started":"2025-12-25T16:31:02.805617Z","shell.execute_reply":"2025-12-25T16:31:02.828747Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Use the trained model to make predictions on the test set\n# These are the scores the model \"thinks\" the students got\ny_pred = regressor.predict(X_test_scaled)\n\n# I compared the first 5 predictions with the actual results\ncomparison_df = pd.DataFrame({'Actual': y_test.values[:5], 'Predicted': y_pred[:5]})\n\nprint(\"--- Actual vs Predicted Values (First 5) ---\")\nprint(comparison_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:31:02.832306Z","iopub.execute_input":"2025-12-25T16:31:02.832654Z","iopub.status.idle":"2025-12-25T16:31:02.860245Z","shell.execute_reply.started":"2025-12-25T16:31:02.832617Z","shell.execute_reply":"2025-12-25T16:31:02.858961Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, r2_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:31:02.861681Z","iopub.execute_input":"2025-12-25T16:31:02.862154Z","iopub.status.idle":"2025-12-25T16:31:02.891039Z","shell.execute_reply.started":"2025-12-25T16:31:02.862116Z","shell.execute_reply":"2025-12-25T16:31:02.889747Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. Calculate Mean Squared Error\nmse = mean_squared_error(y_test, y_pred)\n# 2. Calculate Root Mean Squared Error (Standard deviation of the errors)\nrmse = np.sqrt(mse)\n# 3. Calculate R-squared Score\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"Mean Squared Error (MSE): {mse:.2f}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\nprint(f\"R-squared Score (R2): {r2:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:31:02.892168Z","iopub.execute_input":"2025-12-25T16:31:02.892494Z","iopub.status.idle":"2025-12-25T16:31:02.917228Z","shell.execute_reply.started":"2025-12-25T16:31:02.892466Z","shell.execute_reply":"2025-12-25T16:31:02.915852Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a plotting area\nplt.figure(figsize=(8, 6))\n\n# Scatter plot: Actual values on X-axis, Predicted values on Y-axis\nsns.scatterplot(x=y_test, y=y_pred, alpha=0.6, color='blue')\n\n# sns.regplot draws a scatter plot and fits a regression line\nsns.regplot(x=y_test, y=y_pred, scatter_kws={'alpha':0.5, 'color':'blue'}, line_kws={'color':'red', 'lw':2})\n\nplt.xlabel('Actual Final Percentage')\nplt.ylabel('Predicted Final Percentage')\nplt.title('Actual vs Predicted - Linear Regression')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:31:02.918576Z","iopub.execute_input":"2025-12-25T16:31:02.918915Z","iopub.status.idle":"2025-12-25T16:31:03.282532Z","shell.execute_reply.started":"2025-12-25T16:31:02.918886Z","shell.execute_reply":"2025-12-25T16:31:03.281615Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Ridge Regression (L2 Regularization)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:31:03.283791Z","iopub.execute_input":"2025-12-25T16:31:03.284112Z","iopub.status.idle":"2025-12-25T16:31:03.288814Z","shell.execute_reply.started":"2025-12-25T16:31:03.284087Z","shell.execute_reply":"2025-12-25T16:31:03.287642Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.linear_model import Ridge","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:31:03.290231Z","iopub.execute_input":"2025-12-25T16:31:03.290519Z","iopub.status.idle":"2025-12-25T16:31:03.314037Z","shell.execute_reply.started":"2025-12-25T16:31:03.290483Z","shell.execute_reply":"2025-12-25T16:31:03.312903Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. Initialize Ridge model\n# alpha is the penalty strength (default is 1.0)\nridge_model = Ridge(alpha=1.0)\n# 2. Train the model with scaled data\nridge_model.fit(X_train_scaled, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:31:03.315316Z","iopub.execute_input":"2025-12-25T16:31:03.315618Z","iopub.status.idle":"2025-12-25T16:31:03.354310Z","shell.execute_reply.started":"2025-12-25T16:31:03.315591Z","shell.execute_reply":"2025-12-25T16:31:03.353074Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3. Make predictions\ny_pred_ridge = ridge_model.predict(X_test_scaled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:31:03.355744Z","iopub.execute_input":"2025-12-25T16:31:03.356054Z","iopub.status.idle":"2025-12-25T16:31:03.362809Z","shell.execute_reply.started":"2025-12-25T16:31:03.356026Z","shell.execute_reply":"2025-12-25T16:31:03.361141Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 4. Evaluation\nridge_r2 = r2_score(y_test, y_pred_ridge)\nridge_rmse = np.sqrt(mean_squared_error(y_test, y_pred_ridge))\n\nprint(f\"Ridge Regression R2 Score: {ridge_r2:.4f}\")\nprint(f\"Ridge Regression RMSE: {ridge_rmse:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:31:03.367326Z","iopub.execute_input":"2025-12-25T16:31:03.368143Z","iopub.status.idle":"2025-12-25T16:31:03.388101Z","shell.execute_reply.started":"2025-12-25T16:31:03.368104Z","shell.execute_reply":"2025-12-25T16:31:03.386735Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Extract the intercept\nridge_intercept = ridge_model.intercept_\n\n# Extract the coefficients and pair them with feature names\nridge_coefficients = pd.Series(ridge_model.coef_, index=X.columns)\n\nprint(f\"Ridge Intercept (b0): {ridge_intercept:.4f}\")\nprint(\"\\n--- Ridge Coefficients ---\")\nprint(ridge_coefficients.sort_values(ascending=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:31:03.389342Z","iopub.execute_input":"2025-12-25T16:31:03.389692Z","iopub.status.idle":"2025-12-25T16:31:03.412295Z","shell.execute_reply.started":"2025-12-25T16:31:03.389662Z","shell.execute_reply":"2025-12-25T16:31:03.411183Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.linear_model import RidgeCV\n# 1. Define a list of alpha candidates\n# I test from very small to large values\nalphas = [0.01, 0.1, 1.0, 5.0, 10.0, 20.0, 50.0]\n# 2. Initialize RidgeCV\nridge_cv_model = RidgeCV(alphas=alphas, cv=5)\n# 3. Fit the model to the scaled training data\nridge_cv_model.fit(X_train_scaled, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:31:03.413697Z","iopub.execute_input":"2025-12-25T16:31:03.414190Z","iopub.status.idle":"2025-12-25T16:31:03.533878Z","shell.execute_reply.started":"2025-12-25T16:31:03.414155Z","shell.execute_reply":"2025-12-25T16:31:03.532921Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 4. Results\nprint(f\"The best alpha found by RidgeCV: {ridge_cv_model.alpha_}\")\nprint(f\"R2 Score with best alpha: {ridge_cv_model.score(X_test_scaled, y_test):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:31:03.535149Z","iopub.execute_input":"2025-12-25T16:31:03.535449Z","iopub.status.idle":"2025-12-25T16:31:03.543104Z","shell.execute_reply.started":"2025-12-25T16:31:03.535420Z","shell.execute_reply":"2025-12-25T16:31:03.541923Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Extract coefficients for the best model\nridge_cv_coeffs = pd.Series(ridge_cv_model.coef_, index=X.columns)\nprint(\"\\n--- Coefficients of the Best Ridge Model ---\")\nprint(ridge_cv_coeffs.sort_values(ascending=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:31:03.544299Z","iopub.execute_input":"2025-12-25T16:31:03.544572Z","iopub.status.idle":"2025-12-25T16:31:03.569195Z","shell.execute_reply.started":"2025-12-25T16:31:03.544546Z","shell.execute_reply":"2025-12-25T16:31:03.567782Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Lasso (Least Absolute Shrinkage and Selection Operator) L1 Regularization","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:31:03.570942Z","iopub.execute_input":"2025-12-25T16:31:03.571338Z","iopub.status.idle":"2025-12-25T16:31:03.589360Z","shell.execute_reply.started":"2025-12-25T16:31:03.571297Z","shell.execute_reply":"2025-12-25T16:31:03.587803Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.linear_model import Lasso","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:31:14.835913Z","iopub.execute_input":"2025-12-25T16:31:14.836268Z","iopub.status.idle":"2025-12-25T16:31:14.841551Z","shell.execute_reply.started":"2025-12-25T16:31:14.836239Z","shell.execute_reply":"2025-12-25T16:31:14.840457Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. Initialize Lasso with a specific alpha\nmanual_lasso = Lasso(alpha=0.5)\n# 2. Train the model\nmanual_lasso.fit(X_train_scaled, y_train)\n# 3. Check the results\nlasso_score = manual_lasso.score(X_test_scaled, y_test)\nlasso_coefs = pd.Series(manual_lasso.coef_, index=X.columns)\n\nprint(f\"Lasso (alpha=0.5) R2 Score: {lasso_score:.4f}\")\nprint(\"\\n--- Lasso Coefficients ---\")\nprint(lasso_coefs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:39:19.867210Z","iopub.execute_input":"2025-12-25T16:39:19.867556Z","iopub.status.idle":"2025-12-25T16:39:19.880864Z","shell.execute_reply.started":"2025-12-25T16:39:19.867514Z","shell.execute_reply":"2025-12-25T16:39:19.879742Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.linear_model import LassoCV\n\n# 1. Initialize LassoCV\n# Sometimes Lasso needs more iterations to converge\nlasso_cv = LassoCV(alphas=None, cv=5, max_iter=10000)\n\n# 2. Fit the model to scaled data\nlasso_cv.fit(X_train_scaled, y_train)\n\n# 3. Best alpha and score\nprint(f\"Optimal Alpha found: {lasso_cv.alpha_:.6f}\")\nprint(f\"LassoCV R2 Score: {lasso_cv.score(X_test_scaled, y_test):.4f}\")\n\n# 4. Final Coefficients\nlasso_cv_results = pd.Series(lasso_cv.coef_, index=X.columns)\nprint(\"\\n--- Final LassoCV Coefficients ---\")\nprint(lasso_cv_results.sort_values(ascending=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:41:29.160808Z","iopub.execute_input":"2025-12-25T16:41:29.161168Z","iopub.status.idle":"2025-12-25T16:41:29.233948Z","shell.execute_reply.started":"2025-12-25T16:41:29.161139Z","shell.execute_reply":"2025-12-25T16:41:29.232914Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#ElasticNet L1 (Lasso)+L2 (Ridge)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:43:54.447415Z","iopub.execute_input":"2025-12-25T16:43:54.447775Z","iopub.status.idle":"2025-12-25T16:43:54.453119Z","shell.execute_reply.started":"2025-12-25T16:43:54.447745Z","shell.execute_reply":"2025-12-25T16:43:54.451840Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.linear_model import ElasticNetCV\n\n# 1. Initialize ElasticNetCV\n# l1_ratio: I provided a list of possibilities from Ridge-heavy (0.1) to Lasso-heavy (0.9)\nen_cv_model = ElasticNetCV( l1_ratio=[.1, .5, .7, .9, .95, .99, 1],\n                           alphas=None, \n                           cv=5, \n                           max_iter=10000)\n\n# 2. Fit the model\nen_cv_model.fit(X_train_scaled, y_train)\n\n# 3. Best Parameters\nprint(f\"Optimal L1 Ratio: {en_cv_model.l1_ratio_}\")\nprint(f\"Optimal Alpha: {en_cv_model.alpha_:.6f}\")\nprint(f\"ElasticNetCV R2 Score: {en_cv_model.score(X_test_scaled, y_test):.4f}\")\n\n# 4. Final Coefficients\nen_coeffs = pd.Series(en_cv_model.coef_, index=X.columns)\nprint(\"\\n--- Final ElasticNet Coefficients ---\")\nprint(en_coeffs.sort_values(ascending=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T16:49:11.068860Z","iopub.execute_input":"2025-12-25T16:49:11.069198Z","iopub.status.idle":"2025-12-25T16:49:11.481890Z","shell.execute_reply.started":"2025-12-25T16:49:11.069170Z","shell.execute_reply":"2025-12-25T16:49:11.480916Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}